{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zmkalila/iris-dataset-practice?scriptVersionId=199500657\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Iris Dataset: EDA, Data Visualization, and Classification\n\nI make this notebook based on the codes in this YouTube lesson:  \nhttps://youtu.be/Op3019SFYzI?si=DQ4VwN5I5t8Vk6jX (thus the credit goes to the video-maker).","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"## Import modules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import this module below so when `sns.get_dataset_names()` cell is run, there won't be any warnings.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset","metadata":{}},{"cell_type":"code","source":"sns.get_dataset_names()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = sns.load_dataset('iris') # load dataset\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identify the shape of the dataset","metadata":{}},{"cell_type":"code","source":"df.shape # dataset dimension (number_of_rows, number_of_columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the list of all the column names","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identify data types for each column","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get basic dataset information","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identify missing values","metadata":{}},{"cell_type":"code","source":"df.isna().values.any()\n# can also be written as: df.isnull().values.any()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identify duplicated entries/rows","metadata":{}},{"cell_type":"code","source":"df[df.duplicated(keep=False)] # to display all rows that are duplicated","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop duplicated entries/rows","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)\ndf.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Describe the dataset","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: all the numerical data above is in centimeter (cm) unit.","metadata":{}},{"cell_type":"markdown","source":"## Correlation matrix","metadata":{}},{"cell_type":"code","source":"df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numbers above shows how one variable correlates with the other variables.  \n- **Positive value**: shows that the two variables correlate with each other.<br>(the closer the value to 1, the stronger the correlation is)\n- **Negative value**: shows that the two variables have weak to no correlation.","metadata":{}},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"markdown","source":"## Import modules","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set() # to tell Python that we want the visualization to be in Seaborn style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap","metadata":{}},{"cell_type":"code","source":"sns.heatmap(data=df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].corr(),\n           cmap='rocket_r')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bar Plot","metadata":{}},{"cell_type":"code","source":"df['species'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['species'].value_counts().plot.bar()\nplt.ylabel('Frequency')\nplt.tight_layout()\nplt.xticks(rotation=0)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='species', data=df)\nplt.ylabel('Frequency')\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pie Chart","metadata":{}},{"cell_type":"code","source":"df['species'].value_counts().plot.pie(autopct='%1.1f%%', labels=None, legend=True)\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Line Plot","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(nrows=2, ncols=2, figsize=(10,8))\nplt.suptitle('Iris Sepal & Petal Length Width')\n\ndf['sepal_length'].plot.line(ax=ax[0][0])\nax[0][0].set_title('Sepal Length')\n\ndf['sepal_width'].plot.line(ax=ax[0][1])\nax[0][1].set_title('Sepal Width')\n\ndf.petal_length.plot.line(ax=ax[1][0])\nax[1][0].set_title('Petal Length')\n\ndf.petal_width.plot.line(ax=ax[1][1])\nax[1][1].set_title('Petal Width')\n\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot()\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Histogram","metadata":{}},{"cell_type":"code","source":"df.hist(bins=10)\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.hist(bins=10)\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boxplot","metadata":{}},{"cell_type":"code","source":"df.plot.box()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.box()\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.boxplot(by='species', figsize=(6,6))\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatter Plot","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x='sepal_length', y='sepal_width', data=df, hue='species')\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pair Plot","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df, hue='species', markers='*')\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Violin Plot","metadata":{}},{"cell_type":"code","source":"sns.violinplot(data=df, y='species', x='sepal_length', inner='quartile')\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning: Classification Model","metadata":{}},{"cell_type":"markdown","source":"## Import modules\nScikit-Learn","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split # to split dataset into 2 parts: training & testing set\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report # to evaluate performance of the model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset: Features & Class Label\n\n**'Features'** is the input for the Machine Learning model,\nwhereas **'Class Label'**, as the name suggests, is the output or the labels used for the classification results.\n\nThese 'features' are what the machine will learn to train itself to recognize some pattern in it so that the machine will be able to classify objects into the existing categories, which is the 'Class Labels'.","metadata":{}},{"cell_type":"code","source":"# assign features to variable X\n# only the columns with numerical data becomes the features, thus 'species' column is dropped\n\nX = df.drop(columns='species')\nX.head() # to show the first 5 rows","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the 'species' column acts as the class label (target)\n# assign label (target) to variable y\n\ny = df['species']\ny.head().to_frame() # to show the first 5 rows in the form of dataframe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the dataset into a training set and testing set","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`test_size` is the proportion of the testing dataset.  \n0.4 means 40% testing set and thus the rest (60%) is training set.\n\n`random_state` is the number of the randomization replication.","metadata":{}},{"cell_type":"code","source":"print('training dataset')\nprint(X_train.shape)\nprint(y_train.shape)\nprint()\nprint('testing dataset')\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K Nearest Neighbors","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_range = list(range(1,26))\nscores = [] # empty list\n\nfor k in k_range:\n\n    # configure algorithm by using KNeighborsClassifier function and determine the neighbors number\n    model_knn = KNeighborsClassifier(n_neighbors=k) \n\n    # train model/classifier by using the method .fit() then apply it to X_train and y_train\n    model_knn.fit(X_train, y_train)\n\n    # tell the model to make prediction based on the X_test dataset and assign it to variable y_pred\n    y_pred = model_knn.predict(X_test)\n\n    # lastly see the model's performance based on the accuracy score of the actual performance (y_test) and the trained prediction process (y_pred)\n    scores.append(accuracy_score(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(k_range, scores)\nplt.xlabel('Value of k for KNN')\nplt.ylabel('Accuracy Score')\nplt.title('Accuracy Scores for k values of KNN')\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see above, the accuracy score shows an increasing trend.","metadata":{}},{"cell_type":"code","source":"# model_knn = KNeighborsClassifier(n_neighbors=3)\n# model_knn.fit(X_train, y_train)\n# y_pred = model_knn.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy Score","metadata":{}},{"cell_type":"code","source":"print(accuracy_score(y_test, y_pred)) # to evaluate the accuracy of the classification model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification Report","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_logreg = LogisticRegression(solver='lbfgs', multi_class='auto')\nmodel_logreg.fit(X_train, y_train)\ny_pred = model_logreg.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_svc = SVC(gamma='scale')\nmodel_svc.fit(X_train, y_train)\ny_pred = model_svc.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dt = DecisionTreeClassifier()\nmodel_dt.fit(X_train, y_train)\ny_pred = model_dt.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_rf = RandomForestClassifier(n_estimators=100)\nmodel_rf.fit(X_train, y_train)\npred_rf = model_rf.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy comparison of various classifier models","metadata":{}},{"cell_type":"code","source":"models = [model_knn, model_logreg, model_svc, model_dt, model_rf]\naccuracy_scores = []\n\nfor model in models:\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_scores.append(accuracy)\n\nprint(accuracy_scores)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(['KNN', 'Logistic Regression', 'SVC', 'Decision Tree', 'Random Forest'], accuracy_scores)\nplt.title('Accuracy Score Comparison for Various Classifier Models', fontweight='bold')\nplt.xlabel('Model', fontweight='bold', color='b')\nplt.ylabel('Accuracy Score', fontweight='bold', color='b')\nplt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]}]}